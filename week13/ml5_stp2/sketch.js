/*
 * ğŸ‘‹ Hello! This is an ml5.js example made and shared with â¤ï¸.
 * Learn more about the ml5.js project: https://ml5js.org/
 * ml5.js license and Code of Conduct: https://github.com/ml5js/ml5-next-gen/blob/main/LICENSE.md
 *
 * This example demonstrates face tracking on live video through ml5.faceMesh.
 */

let keyIdx = 0; //í‚¤ë³´ë“œì— ë²„íŠ¼ì„ ëˆ„ë¥´ë©´ ë¹¨ê°„ìƒ‰ìœ¼ë¡œ ë³€í•˜ê²Œ
let mouthOpen = 0;

let faceMesh;
let video;
let faces = [];
let options = { maxFaces: 1, refineLandmarks: false, flipHorizontal: false };

function calcMouthOpen(face) {
  let upper = face.keypoints[13];
  let lower = face.keypoints[14];
  let distance = dist(upper.x, upper.y, upper.z, lower.x, lower.y, lower.z); //ë‘ ì  ì‚¬ì´ì˜ ê±°ë¦¬ êµ¬í•˜ê¸°(3ì°¨ì›ì„ ê³ë“¤ì¸..)
  return distance;
}

//ê±°ë¦¬ ë³´ì • ì¹´ë©”ë¼ì— ê°€ê¹Œì´ ìˆì„ ë–„ ë” í¬ê²Œ ë²Œë¦°ê²ƒì²˜ëŸ¼ë˜ê¸° ë•Œë¬¸ì— ê±°ë¦¬ì— ê´€ê³„ì—†ì´ ê°™ì€ í¬ê¸°ë¡œ ë²Œë¦¬ë©´ ê°™ì€ ê°’ì´ ë‚˜ì˜¤ë„ë¡ í•  ìˆ˜ ë„ ìˆë‹¤.
//ê´€ìë†€ì´ë¥¼ ê¸°ì¤€ìœ¼ë¡œ í•¨ 21ë²ˆì¨° ì ê³¼ 251ë²ˆì¨° ì ì´ ì¢Œìš° ê´€ìë†€ì´ìª½ì˜ ì ì´ë‹¤.
// ì…ìˆ  ì‚¬ì´ ê±°ë¦¬ë¥¼ ì´ ê°’ìœ¼ë¡œ ë‚˜ëˆ ì¤€ë‹¤?ì¢€ í—·ê°ˆë¦¼ --ê·¸ë˜ì•¼ ë³´ì •ì¹˜ê°€ ë¨
function calcWidth(face) {
  let left = face.keypoints[21];
  let right = face.keypoints[251];
  let distance = dist(left.x, left.y, left.z, right.x, right.y, right.z);
  return distance;
}

function keyPressed() {
  //===:3 ê°œ ìˆ«ìë¡œì„œ 0ê³¼ ê¸€ìë¡œì„œ 0ì´ ìˆë‹¤. ì„¸ê°œì“°ë©´ ìˆ«ì 0 ë§Œ ì¸ì‹í•˜ê³   ==:2ê°œ ë©´ ê¸€ì, ìˆ«ì ë‘˜ë‹¤ 0ì´ë©´ ì¸ì‹
  if (keyCode === RIGHT_ARROW) {
    keyIdx++;
  } else if (keyCode === LEFT_ARROW) {
    keyIdx--;
  }

  if (keyIdx < 0) {
    keyIdx = 0;
  }
  console.log('Current Idx : ', keyIdx);
}

function preload() {
  // Load the faceMesh model
  faceMesh = ml5.faceMesh(options);
}

function setup() {
  createCanvas(640, 480);
  // Create the webcam video and hide it
  video = createCapture(VIDEO);
  video.size(640, 480);
  video.hide();
  // Start detecting faces from the webcam video
  faceMesh.detectStart(video, gotFaces);
}

function draw() {
  // Draw the webcam video
  image(video, 0, 0, width, height);

  // Draw all the tracked face points
  for (let i = 0; i < faces.length; i++) {
    let face = faces[i];
    for (let j = 0; j < face.keypoints.length; j++) {
      let keypoint = face.keypoints[j];
      if (keyIdx === j) {
        fill(255, 0, 0);
      } else {
        fill(0, 255, 0);
      }
      noStroke();
      circle(keypoint.x, keypoint.y, 5);
    }
    let faceWidth = calcWidth(face);
    console.log('ê±°ë¦¬ ê¸°ì¤€ê°’:', faceWidth);

    let mouthDist = calcMouthOpen(face);

    let normalMouth = mouthDist / faceWidth;
    console.log('ì •ê·œí™”ëœ ì…: ', normalMouth);
    // let fWeight = map(mouthDist, 0, 100, 100, 900);
    let fWeight = map(normalMouth, 0, 0.33, 100, 900);
    // console.log(mouthDist);

    //documentëŠ” jsê°€ ì‹¤í–‰ë˜ê³  ìˆëŠ” htmlì„ ê°€ë¦¬í‚¤ê²Œ ëœë‹¤.cssìŠ¤íƒ€ì¼ ì ìš©
    document.documentElement.style.setProperty('--fWeight', fWeight);
  }
}

// Callback function for when faceMesh outputs data
function gotFaces(results) {
  // Save the output to the faces variable
  faces = results;
}

//ì–¼êµ´ì— ì € ì„¸ê°œë¥¼ ì°ê³  ì–¼êµ´ì„ ëŒë ¸ì„ë–„ ê°’ì„ ê³„ì‚°í•  ìˆ˜ ìˆë‹¤.
// ì±— ì§€í”¼í‹° : facemeshë¥¼ í†µí•´ì„œ ì–¼êµ´ì˜ ì •ì  ë°ì´í„°ë¥¼ ê°€ì§€ê³  ìˆë‹¤. ì´ ì¤‘ì— ì„¸ ì ì„ ì¶”ë ¤ì„œ ì–¼êµ´ì´ ì–´ëŠ ë°©í–¥ìœ¼ë¡œ í–¥í•˜ëŠ”ì§€ ê³„ì‚°í•  ìˆ˜ ìˆëŠ” í•¨ìˆ˜ë¥¼ ì‘ì„±í•´ì¤˜ ë¼ê³  ë¬¼ì–´ë³´ì…ˆ
//xyz ê°’ì„ íšŒì „ì‹œí‚¤ë©´ ë¨ yaw, pitch , roll
